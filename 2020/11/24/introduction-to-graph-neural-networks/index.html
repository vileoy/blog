<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>图神经网络简介 - vileoy&#039;s blog</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="vileoy&#039;s blog"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-21-favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="vileoy&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="近年来，图神经网络（GNNs）在社交网络、知识图谱、推荐系统甚至生命科学等各个领域得到越来越广泛的应用。本文将对图神经网络的一般框架，即消息传递形式体系，进行介绍；并在此基础上讨论一些基础的图神经网络模型。"><meta property="og:type" content="blog"><meta property="og:title" content="图神经网络简介"><meta property="og:url" content="https://vileoy.uovie.com/blog/2020/11/24/introduction-to-graph-neural-networks/"><meta property="og:site_name" content="vileoy&#039;s blog"><meta property="og:description" content="近年来，图神经网络（GNNs）在社交网络、知识图谱、推荐系统甚至生命科学等各个领域得到越来越广泛的应用。本文将对图神经网络的一般框架，即消息传递形式体系，进行介绍；并在此基础上讨论一些基础的图神经网络模型。"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-gnn-cover.png"><meta property="article:published_time" content="2020-11-24T08:47:29.035Z"><meta property="article:modified_time" content="2020-11-24T11:28:22.781Z"><meta property="article:author" content="Haoyu Lin"><meta property="article:tag" content="Neural Network"><meta property="article:tag" content="Graph"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-gnn-cover.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://vileoy.uovie.com/blog/2020/11/24/introduction-to-graph-neural-networks/"},"headline":"vileoy's blog","image":["https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-gnn-cover.png"],"datePublished":"2020-11-24T08:47:29.035Z","dateModified":"2020-11-24T11:28:22.781Z","author":{"@type":"Person","name":"Haoyu Lin"},"description":"近年来，图神经网络（GNNs）在社交网络、知识图谱、推荐系统甚至生命科学等各个领域得到越来越广泛的应用。本文将对图神经网络的一般框架，即消息传递形式体系，进行介绍；并在此基础上讨论一些基础的图神经网络模型。"}</script><link rel="canonical" href="https://vileoy.uovie.com/blog/2020/11/24/introduction-to-graph-neural-networks/"><link rel="icon" href="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-21-favicon.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-0-logo.png" alt="vileoy&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" href="/blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/vileoy"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-gnn-cover.png" alt="图神经网络简介"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-11-24T08:47:29.035Z" title="2020-11-24T08:47:29.035Z">2020-11-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-24T11:28:22.781Z" title="2020-11-24T11:28:22.781Z">2020-11-24</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/blog/categories/Machine-Learning/Graph-Neural-Networks/">Graph Neural Networks</a></span><span class="level-item">25 minutes read (About 3753 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">图神经网络简介</h1><div class="content"><p>近年来，图神经网络（GNNs）在社交网络、知识图谱、推荐系统甚至生命科学等各个领域得到越来越广泛的应用。本文将对图神经网络的一般框架，即消息传递形式体系，进行介绍；并在此基础上讨论一些基础的图神经网络模型。</p>
<a id="more"></a>
<h2 id="前言">前言</h2>
<p>深度学习在许多领域取得了可喜的进展，如计算机视觉和自然语言处理。这些任务中的数据通常在欧几里得域中表示。然而，许多学习任务需要处理包含丰富元素间关系信息的非欧几里得的图数据，如建模物理系统、学习分子指纹、预测蛋白质界面等[1]。图神经网络（GNNs）是图域上的深度学习模型，由于其令人信服的性能和较高的可解释性，已成为近年来广泛应用的图分析方法[2]。这篇贴子提供了对图神经网络的基本概念、模型和应用的简单介绍。</p>
<h2 id="消息传递形式体系">消息传递形式体系</h2>
<p>图神经网络是一种定义在图数据<span class="math inline">\(\mathbb{G} = (\mathbb{V}; \mathbb{E})\)</span>上深度神经网络的一般框架，通过自动学习节点嵌入、图嵌入作为图的表示，进而做出预测。其关键思想是，通过机器学习生成仅依赖于图形结构以及可能拥有的任何特征信息的节点表示。各种图神经网络可以表示为一种邻域聚集（neighborhood aggregation）或消息传递（message passing）。在这个框架下，图神经网络通过两个步骤将图形映射到输出。首先，有一个传播步骤，计算每个节点的节点表示；其次，输出模型<span class="math inline">\(\hat{y}_{v} = g(h_v; x_v)\)</span>从节点表示和相应的标签映射到每个节点的输出<span class="math inline">\(o_v\)</span>。</p>
<p>消息传递的前向传播有两个阶段，消息传递阶段（message passing phase）和读出阶段（readout phase）[3]。消息传递阶段通常经过<span class="math inline">\(T\)</span>时间步的迭代，单个时间步根据消息函数<span class="math inline">\(\mathcal{M}_{t}\)</span>和顶点更新函数<span class="math inline">\(\mathcal{U}_{t}\)</span>定义。在消息传递阶段，图中每个节点的隐藏状态<span class="math inline">\(h_{t+1,v_{i}}\)</span>根据消息<span class="math inline">\(m_{t+1,v_{i}}\)</span>更新[3]： <span class="math display">\[
m_{t+1,v_{i}} = \mathcal{A}(\{\mathcal{M}_{t}(h_{t,v_{i}}, h_{t,v_{j}}, h_{t,e_{ij}}) | v_{j} \in \mathcal{N}(v_{i})\}),
\]</span> <span class="math display">\[
h_{t+1,v_{i}} = \mathcal{U}_{t}(h_{t,v_{i}}, m_{t+1,v_{i}}).
\]</span></p>
<p>其中<span class="math inline">\(\mathcal{A}\)</span>为聚集方案，例如sum、mean、max；<span class="math inline">\(\mathcal{N}(v_{i})\)</span>表示图<span class="math inline">\(\mathbb{G}\)</span>中<span class="math inline">\(v_{i}\)</span>的邻居。当有多个边类型时，我们必须定义多个消息函数<span class="math inline">\(\mathcal{M}_{t,\operatorname{type}(e_{ij})}\)</span>，它是<span class="math inline">\(t\)</span>层边类型为<span class="math inline">\(\operatorname{type}(e_{ij})\)</span>的消息函数。</p>
<p>读出阶段使用一种读出函数<span class="math inline">\(\mathcal{O}\)</span>计算整个图的特征矢量（feature vector），也就是嵌入（embedding）。 <span class="math display">\[
\hat{y} = \mathcal{O}(\{h_{v} ; x_{v} | v \in \mathbb{V}\}).
\]</span> 这种香草形式体系是由Scarselli等人[2009]首先提出的[4]，后来被称为消息传递范式[3]。</p>
<h2 id="图卷积神经网络">图卷积神经网络</h2>
<p>卷积神经网络（CNNs）可以提取出数据的空间关联信息，因此在深度学习领域取得了巨大的成功。自然地，我们也可以尝试将其推广至图，学习节点间的空间关联，从而提取图的结构信息。在这个方向上的研究通常可以归类为谱方法（spectral approaches）和空间方法（spatial approaches）[1]。</p>
<p>Bruna等人[2014]提出了谱网络[5]。通过计算图的拉普拉斯特征分解，在傅里叶域中定义了卷积运算。操作可以被定义为一个信号<span class="math inline">\(\mathbf{x} \in \mathbb{R}^{N}\)</span>与一个由<span class="math inline">\(\mathbf{\theta} \in \mathbb{R}^{N}\)</span>参数化的过滤器<span class="math inline">\(\mathbf{g}_{\theta} = \operatorname{diag}(\mathbf{\theta})\)</span>的乘积： <span class="math display">\[
\mathbf{g}_{\theta} * \mathbf{x} = \mathbf{U} \mathbf{g}_{\theta}(\Lambda) \mathbf{U}^{\text{T}} \mathbf{x},
\]</span> 式中，<span class="math inline">\(\mathbf{U}\)</span>是对称正规化的图拉普拉斯<span class="math inline">\(\mathbf{L} = \mathbf{I}_{N} - \mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{-\frac{1}{2}} = \mathbf{U} \Lambda \mathbf{U}^{\text{T}}\)</span>的本征矢量矩阵，<span class="math inline">\(\Lambda\)</span>是对角线为本征值的对角矩阵。</p>
<p>不过这个操作的计算难度特别高，所以必须做近似处理，降低计算消耗。Hammond等人[2011]指出<span class="math inline">\(\mathbf{g}_{\theta}(\Lambda)\)</span>可以用一个截断的切比雪夫多项式<span class="math inline">\(\mathbf{T}_{k}(x)\)</span>近似[6]。根据此方法，Defferrard等人[2016]提出了ChebNet，它使用<span class="math inline">\(K\)</span>-局域卷积来定义卷积神经网络，可以消除对拉普拉斯特征向量的计算[7]。</p>
<p>后来Kipf和Welling[2017]将卷积操作只展开到<span class="math inline">\(k = 1\)</span>阶，并做了一些其他近似，然后提出了至今广泛使用的图卷积神经网络（GCN）[8]。利用消息传递的框架，我们可以将其表述成： <span class="math display">\[
m_{t+1,v_{i}} = \sum_{v_{j} \in \mathcal{N}(v_{i}) \cup v_{i}} \frac{W_{t} h_{t,v_{j}}}{\sqrt{\operatorname{deg}(v_{i}) \operatorname{deg}(v_{j})}},
\]</span></p>
<p><span class="math display">\[
h_{t+1,v_{i}} = \operatorname{ReLU}(W_{t}^{\prime} m_{t+1,v_{i}}).
\]</span></p>
<p>也就是说，在邻近的节点特征或者隐藏状态是先由权重矩阵<span class="math inline">\(W_{t}\)</span>做线性变化，再通过度的规范化，最后加起来（包含自身节点）得到局部图结构下的消息。这个消息然后传到一个全连接的神经网络层生成新的节点状态（隐藏状态或者嵌入）。为了更好地理解图卷积神经网络，我们可以参考PyTorch geometric的GCN实现<a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gcn_conv.html#GCNConv">PyTorch geometric: GCNConv</a>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCNConv</span>(<span class="params">MessagePassing</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span></span><br><span class="line">        super(GCNConv, self).__init__(aggr=<span class="string">&#x27;add&#x27;</span>)</span><br><span class="line">        self.lin = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, edge_index</span>):</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line">        x = self.lin(x)</span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.pow(<span class="number">-0.5</span>)</span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line">        <span class="keyword">return</span> self.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span>(<span class="params">self, x_j, norm</span>):</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(<span class="number">-1</span>, <span class="number">1</span>) * x_j</span><br></pre></td></tr></table></figure>
<p>最后值得注意的是，作为谱方法的简化，图卷积神经网络（GCN）模型也可以看作是一种空间方法。</p>
<h2 id="图循环神经网络">图循环神经网络</h2>
<p>图神经网络的发展还有一个趋势，那就是在传播步骤使用循环神经网络（RNNs）的门机制，比如GRU、LSTM，以提高图中长期信息传播的有效性。Li等人[2016]提出门控图神经网络（GGNN）它在传播步骤中使用了门循环单元[9]。该模型中，消息函数为<span class="math inline">\(\mathcal{M}_{t}(h_{t,v_{i}}, h_{t,v_{j}}, h_{t,e_{ij}}) = W_{t} h_{t,v_{j}}\)</span>，聚合方案<span class="math inline">\(\mathcal{A}\)</span>为sum，更新函数为<span class="math inline">\(\mathcal{U}_{t}(h_{t,v_{i}}, m_{t+1,v_{i}}) = \operatorname{GRU}(h_{t,v_{i}}, m_{t+1,v_{i}})\)</span>。因此，消息是由 <span class="math display">\[
m_{t+1,v_{i}} = \sum_{v_{j} \in \mathcal{N}(v_{i})} W_{t} h_{t,v_{j}}
\]</span> 生成的，其中<span class="math inline">\(h_{0,v_{j}} = [x_{v_{j}} ; 0]\)</span>是节点特征用零一直填充到<span class="math inline">\(\text{out_channels} \times \text{out_channels}\)</span>维数得到的初始隐藏状态。接下来，门控循环单元被调用来更新隐藏的嵌入： <span class="math display">\[
h_{t+1,v_{i}} = \operatorname{GRU}(h_{t,v_{i}}, m_{t+1,v_{i}}).
\]</span> 更新函数的详细过程可展开如下： <span class="math display">\[
z_{t,v_{i}} = \sigma(W_{z,m} m_{t+1,v_{i}} + W_{z,h} h_{t,v_{i}} + b_{z}),
\]</span></p>
<p><span class="math display">\[
r_{t,v_{i}} = \sigma(W_{r,m} m_{t+1,v_{i}} + W_{r,h} h_{t,v_{i}} + b_{r}),
\]</span></p>
<p><span class="math display">\[
\tilde{h}_{t+1,v_{i}} = \tanh(W_{c,m} m_{t+1,v_{i}} + W_{c,h} (r_{t,v_{i}} \odot h_{t,v_{i}})),
\]</span></p>
<p><span class="math display">\[
h_{t+1,v_{i}} = (1 - z_{t,v_{i}}) \odot h_{t,v_{i}} + z_{t,v_{i}} \odot \tilde{h}_{t+1,v_{i}}.
\]</span></p>
<p>正如你所看到的，<span class="math inline">\(t+1\)</span>层的隐藏状态<span class="math inline">\(h_{t+1,v_{i}}\)</span>是之前隐藏状态<span class="math inline">\(h_{t,v_{i}}\)</span>和候选激活<span class="math inline">\(\tilde{h}_{t+1,v_{i}}\)</span>之间的线性插值。</p>
<p>将节点表示和对应的标签映射到期望输出的输出函数采用如下形式： <span class="math display">\[
\mathcal{O}(h_{T,v}, h_{0,v}) = \tanh\left(\sum_{v \in \mathbb{V}} \sigma(\operatorname{NN}_{a}(h_{T,v}, h_{0,v})) \odot \tanh(\operatorname{NN}_{b}(h_{T,v}, h_{0,v}))\right),
\]</span> 式中，<span class="math inline">\(\sigma(\operatorname{NN}_{a}(h_{T,v}, h_{0,v}))\)</span>作为一个软注意机制，决定哪些节点与当前的图级（graph-level）任务相关。<span class="math inline">\(\operatorname{NN}_{a}\)</span>和<span class="math inline">\(\operatorname{NN}_{b}\)</span>是两个神经网络，以<span class="math inline">\(h_{T,v}\)</span>和<span class="math inline">\(h_{0,v}\)</span>作为输入，输出实值矢量。另外，<span class="math inline">\(\tanh\)</span>函数也可以用恒等函数代替。GGNN的实现可以参考<a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gated_graph_conv.html#GatedGraphConv">PyTorch geometric: GatedGraphConv</a>。</p>
<h2 id="图注意力神经网络">图注意力神经网络</h2>
<p>注意机制已成功地应用在许多基于序列的任务，例如机器翻译、机器阅读等等。注意力函数可以描述为将查询和一组键-值对到输出的映射，其中查询、键、值和输出都是矢量[10]。输出以值的加权和的形式计算，其中分配给每个值的权重由查询与相应键的兼容函数计算。可以用下式紧凑地表述注意力机制： <span class="math display">\[
\operatorname{Attention}(Q,K,V) = \operatorname{Compatibility}(Q,K)V.
\]</span> 与同等对待一个节点的所有邻居的图卷积神经网络相比，注意机制可以给每个邻居分配不同的注意分数，从而识别出更重要的邻居。所以将注意力机制引入图神经网络可以在某种程度上增强网络的学习能力。Velickovic等人[2017]提出一个图注意力网络（GAT），在图神经网络的传播步骤中并入了注意力机制机制。该算法采用自注意策略，通过有所侧重地关注其邻居来计算每个节点的隐藏状态[11]。</p>
<p>为了将输入特征转换成高阶的特征从而获得足够的表达能力，我们至少需要一个可学习的线性变换。为此，作为初始步骤，对每个节点应用一个共同的变换矩阵为可学习的权值矩阵<span class="math inline">\(W \in \mathbb{R}^{F&#39; \times F}\)</span>的线性变换，将特征矢量投影到更具表现力的空间。然后我们在节点上执行相同的自注意力机制，<span class="math inline">\(\operatorname{Attention}: \mathbb{R}^{F&#39;} \times \mathbb{R}^{F} \to \mathbb{R}\)</span>，来计算注意系数： <span class="math display">\[
e_{ij} = \operatorname{Attention}(W h_{v_{i}},W h_{v_{j}}),
\]</span> 这指出了节点<span class="math inline">\(v_{j}\)</span>的特征对节点<span class="math inline">\(v_{i}\)</span>的重要性。为了使系数在不同节点之间易于比较，我们使用softmax函数对系数进行归一化： <span class="math display">\[
\alpha_{ij} = \operatorname{softmax}(e_{ij}) = \frac{\exp(e_{ij})}{\sum_{k \in \mathcal{N}_{i}} \exp(e_{ik})}.
\]</span> 在Velickovic等人[2017]的工作中，注意机制<span class="math inline">\(\operatorname{Attention}\)</span>是一个单层的前馈神经网络，由权值向量<span class="math inline">\(a \in \mathbb{R}^{2F&#39;}\)</span>参数化，并采用LeakyReLU非线性单元（负输入的斜率为0.2）。完全展开后，由注意机制计算出的系数可表示为: <span class="math display">\[
\alpha_{i j} = \frac{\exp \left(\operatorname{ LeakyReLU }\left(a^{\text{T}} [W h_{v_i} \| W h_{v_j}]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\operatorname{ LeakyReLU }\left(a^{\text{T}} [W h_{v_i} \| W h_{v_k}]\right)\right)},
\]</span> 式中，<span class="math inline">\(\|\)</span>表示连结操作。</p>
<p><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-to-gnn-attention.png" alt="Attention" style="zoom:50%;" /></p>
<p>然后每个节点的最终输出特性可以通过下式获得： <span class="math display">\[
h_{v_i}^{\prime} = \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} W h_{v_j}\right).
\]</span> 为了稳定自注意的学习过程，扩展至多头注意力机制是有益的。具体的做法就是，采用<span class="math inline">\(K\)</span>个独立的注意机制一起执行上式的变换，然后将它们的聚合。聚合可以是连结，也可以是取平均： <span class="math display">\[
h_{v_i}^{\prime} = \|_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} W^{k} h_{v_j}\right) \quad \text{or} \quad h_{v_i}^{\prime} = \sigma\left(\frac{1}{K} \sum_{k=1}^{K} \sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} W^{k} h_{v_j}\right).
\]</span> 下图是对多头注意力机制的形象的图形描述，需要注意的是它有个自连接线，考虑了其本身的重要性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-to-gnn-multi-head-attention.png" alt="Multi-head Attention" style="zoom:50%;" /></p>
<p>GAT的实现可以参考<a target="_blank" rel="noopener" href="https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gat%20conv.html#GATConv">PyTorch geometric: GATConv</a>。</p>
<p>Velickovic等人[2018]提出的这种注意架构有几个性质：（1）节点近邻对的计算是并行的，因此操作是高效的；（2）可以对不同程度的节点进行处理，并为其相邻节点分配相应的权重；（3）易应用于归纳学习问题。因此，在半监督节点分类、链路预测等任务中，GAT的性能优于GCN。</p>
<h2 id="结语">结语</h2>
<p>此贴以消息传递的基本概念开始，介绍了图神经网络的基本框架，旨在为读者提供一个一般性的概述。然后介绍三个不同的图神经网络变体：图卷积神经网络、图循环神经网络、图注意力神经网络。这些变体是各种不同深度学习技术在图上的推广，是机器学习在非欧流形的普及。目前，图神经网络在结构场景（物理、化学、知识图）、非结构场景（图像、文本）和其他场景（生成模型、组合优化）中都有广泛的应用，并取得了不错的进展[1]。希望此文对想要学习图神经网络的读者有所帮助。</p>
<h2 id="参考文献">参考文献</h2>
<ol type="1">
<li>Liu, Zhiyuan. <em>Introduction to Graph Neural Networks</em>. Morgan &amp; Claypool Publishers, 2020, ISBN:978-1-68173-767-6.</li>
<li>Hamilton, William. <em>Graph Representation Learning</em>. Morgan &amp; Claypool Publishers, 2020, ISBN:978-1-68173-963-2.</li>
<li>Gilmer, Justin, et al. “Neural Message Passing for Quantum Chemistry.”, 2017, arXiv:1704.01212.</li>
<li>Scarselli, F., et al. “The Graph Neural Network Model.” Transactions on Neural Networks, vol. 20, no. 1, Jan. 2009, pp. 61–80. DOI:10.1109/tnn.2008.2005605.</li>
<li>Bruna, Joan, et al. “Spectral Networks and Locally Connected Networks on Graphs.” , 2013, arXiv:1312.6203.</li>
<li>Hammond, David K., et al. “Wavelets on graphs via spectral graph theory.” Applied and Computational Harmonic Analysis, vol. 30, no. 2, Mar. 2011, pp. 129–150. DOI:10.1016/j.acha.2010.04.005.</li>
<li>Defferrard, Michaël, et al. “Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering.”, 2016, arXiv:1606.09375.</li>
<li>Kipf, Thomas N. and Max Welling. “Semi-Supervised Classification with Graph Convolutional Networks.”, 2016, arXiv:1609.02907.</li>
<li>Li, Yujia, et al. “Gated Graph Sequence Neural Networks.”, 2015, arXiv:1511.05493.</li>
<li>Vaswani, Ashish, et al. “Attention Is All You Need.”, 2017, arXiv:1706.03762.</li>
<li>Veličković, Petar, et al. “Graph Attention Networks.”, 2017, arXiv:1710.10903.</li>
<li>Wu, Zonghan, et al. “A Comprehensive Survey on Graph Neural Networks.” Transactions on Neural Networks and Learning Systems, 2020, pp. 1–21. DOI:10.1109/tnnls.2020.2978386.</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>图神经网络简介</p><p><a href="https://vileoy.uovie.com/blog/2020/11/24/introduction-to-graph-neural-networks/">https://vileoy.uovie.com/blog/2020/11/24/introduction-to-graph-neural-networks/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Haoyu Lin</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-11-24</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2020-11-24</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/Neural-Network/">Neural Network</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Graph/">Graph</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5eb624fd6fa8080012c68782&amp;product=sticky-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/alipay-qrcode.jpg" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wechat-qrcode.png" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2020/11/04/music-score-season-song/"><span class="level-item">Music Score: Season Song</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.2/gitalk.css"><script src="https://cdnjs.loli.net/ajax/libs/gitalk/1.6.2/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "65d26908d723473e5c8341f0db2a2575",
            repo: "blog",
            owner: "vileoy",
            clientID: "7dc49be522b0781c0b39",
            clientSecret: "33315fe6f9dd14cf774f83d746e462de45ebdaeb",
            admin: ["vileoy"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 15,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://cdn.jsdelivr.net/gh/vileoy/source/images/avatar-kousei.jpg" alt="Haoyu Lin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Haoyu Lin</p><p class="is-size-6 is-block">PhD Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Haidian, Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">26</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/vileoy" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/vileoy"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Wechat" href="account:vileoy"><i class="fab fa-weixin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="E-Mail" href="mailto:vileoy@pku.edu.cn"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/vileoy"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/blog/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#前言"><span class="level-left"><span class="level-item">1</span><span class="level-item">前言</span></span></a></li><li><a class="level is-mobile" href="#消息传递形式体系"><span class="level-left"><span class="level-item">2</span><span class="level-item">消息传递形式体系</span></span></a></li><li><a class="level is-mobile" href="#图卷积神经网络"><span class="level-left"><span class="level-item">3</span><span class="level-item">图卷积神经网络</span></span></a></li><li><a class="level is-mobile" href="#图循环神经网络"><span class="level-left"><span class="level-item">4</span><span class="level-item">图循环神经网络</span></span></a></li><li><a class="level is-mobile" href="#图注意力神经网络"><span class="level-left"><span class="level-item">5</span><span class="level-item">图注意力神经网络</span></span></a></li><li><a class="level is-mobile" href="#结语"><span class="level-left"><span class="level-item">6</span><span class="level-item">结语</span></span></a></li><li><a class="level is-mobile" href="#参考文献"><span class="level-left"><span class="level-item">7</span><span class="level-item">参考文献</span></span></a></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/blog/js/toc.js" defer></script></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/03/"><span class="level-start"><span class="level-item">March 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://uovie.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">UOVIE</span></span><span class="level-right"><span class="level-item tag">uovie.com</span></span></a></li><li><a class="level is-mobile" href="https://lkoit.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">LKOIT</span></span><span class="level-right"><span class="level-item tag">lkoit.com</span></span></a></li><li><a class="level is-mobile" href="https://chemairy.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Chemairy</span></span><span class="level-right"><span class="level-item tag">chemairy.com</span></span></a></li><li><a class="level is-mobile" href="https://fairy.dance" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Fairy Dance</span></span><span class="level-right"><span class="level-item tag">fairy.dance</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/11/24/introduction-to-graph-neural-networks/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-gnn-cover.png" alt="图神经网络简介"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-11-24T08:47:29.035Z">2020-11-24</time></p><p class="title"><a href="/blog/2020/11/24/introduction-to-graph-neural-networks/">图神经网络简介</a></p><p class="categories"><a href="/blog/categories/Machine-Learning/">Machine Learning</a> / <a href="/blog/categories/Machine-Learning/Graph-Neural-Networks/">Graph Neural Networks</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/11/04/music-score-season-song/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-4d31xg.jpg" alt="Music Score: Season Song"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-11-04T03:02:50.000Z">2020-11-04</time></p><p class="title"><a href="/blog/2020/11/04/music-score-season-song/">Music Score: Season Song</a></p><p class="categories"><a href="/blog/categories/Music/">Music</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/10/21/champs-kaggle-competition-predicting-scalar-coupling-constants/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-kwjor6.jpg" alt="Champs Kaggle Competition: Predicting Scalar Coupling Constants"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-10-21T06:58:37.360Z">2020-10-21</time></p><p class="title"><a href="/blog/2020/10/21/champs-kaggle-competition-predicting-scalar-coupling-constants/">Champs Kaggle Competition: Predicting Scalar Coupling Constants</a></p><p class="categories"><a href="/blog/categories/Molecular-Modeling/">Molecular Modeling</a> / <a href="/blog/categories/Molecular-Modeling/Molecular-Property-Prediction/">Molecular Property Prediction</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/10/09/computer-aided-synthesis-planning-a-brief-introduction/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-73v1x3.jpg" alt="Computer-Aided Synthesis Planning: A Brief Introduction"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-10-08T16:21:42.990Z">2020-10-09</time></p><p class="title"><a href="/blog/2020/10/09/computer-aided-synthesis-planning-a-brief-introduction/">Computer-Aided Synthesis Planning: A Brief Introduction</a></p><p class="categories"><a href="/blog/categories/Synthesis-Planning/">Synthesis Planning</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/10/09/message-passing-neural-networks/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-4dk19g.jpg" alt="Message Passing Neural Networks"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-10-08T16:21:42.990Z">2020-10-09</time></p><p class="title"><a href="/blog/2020/10/09/message-passing-neural-networks/">Message Passing Neural Networks</a></p><p class="categories"><a href="/blog/categories/Machine-Learning/">Machine Learning</a> / <a href="/blog/categories/Machine-Learning/Graph-Neural-Networks/">Graph Neural Networks</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/categories/Chemoinformatics/"><span class="level-start"><span class="level-item">Chemoinformatics</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Chemoinformatics/Conventions/"><span class="level-start"><span class="level-item">Conventions</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Game/"><span class="level-start"><span class="level-item">Game</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/LaTeX/"><span class="level-start"><span class="level-item">LaTeX</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Graph-Neural-Networks/"><span class="level-start"><span class="level-item">Graph Neural Networks</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Reinforcement-Learning/"><span class="level-start"><span class="level-item">Reinforcement Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Molecular-Dynamics/"><span class="level-start"><span class="level-item">Molecular Dynamics</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Molecular-Dynamics/Free-Energy-Calculation/"><span class="level-start"><span class="level-item">Free Energy Calculation</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Molecular-Modeling/"><span class="level-start"><span class="level-item">Molecular Modeling</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Molecular-Modeling/Molecular-Property-Prediction/"><span class="level-start"><span class="level-item">Molecular Property Prediction</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Molecular-Modeling/Scoring-Function/"><span class="level-start"><span class="level-item">Scoring Function</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Music/"><span class="level-start"><span class="level-item">Music</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Parallel-Programming/"><span class="level-start"><span class="level-item">Parallel Programming</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Synthesis-Planning/"><span class="level-start"><span class="level-item">Synthesis Planning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/Activation-Function/"><span class="tag">Activation Function</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Attention-Mechanism/"><span class="tag">Attention Mechanism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/BibTeX/"><span class="tag">BibTeX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Binding-Affinity/"><span class="tag">Binding Affinity</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/C-Thread-Library/"><span class="tag">C++ Thread Library</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Chrome/"><span class="tag">Chrome</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Conda/"><span class="tag">Conda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/DOI/"><span class="tag">DOI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Dino/"><span class="tag">Dino</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Free-Energy/"><span class="tag">Free Energy</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Graph/"><span class="tag">Graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ISBN/"><span class="tag">ISBN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Loss-Function/"><span class="tag">Loss Function</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Message-Passing-Interface/"><span class="tag">Message Passing Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Mol2/"><span class="tag">Mol2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Music-Score/"><span class="tag">Music Score</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Neural-Network/"><span class="tag">Neural Network</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Perturbation-Theory/"><span class="tag">Perturbation Theory</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Protein%E2%88%92Ligand-Complex/"><span class="tag">Protein−Ligand Complex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Python/"><span class="tag">Python</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Q-Learning/"><span class="tag">Q-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/R/"><span class="tag">R</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/RDKit/"><span class="tag">RDKit</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Reinforcement-Learning/"><span class="tag">Reinforcement Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Retrosynthesis/"><span class="tag">Retrosynthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Route-Planning/"><span class="tag">Route Planning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/SSH/"><span class="tag">SSH</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Scalar-Coupling/"><span class="tag">Scalar Coupling</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Scoring-Function/"><span class="tag">Scoring Function</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Structure-Preparation/"><span class="tag">Structure Preparation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Tripos/"><span class="tag">Tripos</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Tutorial/"><span class="tag">Tutorial</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Workflow/"><span class="tag">Workflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/arXiv/"><span class="tag">arXiv</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-0-logo.png" alt="vileoy&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Haoyu Lin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/vileoy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>