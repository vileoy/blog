<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Temporal Difference Learning - vileoy&#039;s blog</title><link rel="manifest" href="/blog/manifest.json"><meta name="application-name" content="vileoy&#039;s blog"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-21-favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="vileoy&#039;s blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="In this post, we will now introduce a RL method called TD learning, which can be considered as an improvement or extension of the MC-based RL approach. Similar to the MC technique, TD learning is also"><meta property="og:type" content="blog"><meta property="og:title" content="Temporal Difference Learning"><meta property="og:url" content="https://vileoy.uovie.com/blog/2020/05/14/temporal_difference_learning/"><meta property="og:site_name" content="vileoy&#039;s blog"><meta property="og:description" content="In this post, we will now introduce a RL method called TD learning, which can be considered as an improvement or extension of the MC-based RL approach. Similar to the MC technique, TD learning is also"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-q6gxpl.png"><meta property="article:published_time" content="2020-05-14T09:36:09.000Z"><meta property="article:modified_time" content="2020-10-29T03:40:08.116Z"><meta property="article:author" content="Haoyu Lin"><meta property="article:tag" content="Reinforcement Learning"><meta property="article:tag" content="Q-Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-q6gxpl.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://vileoy.uovie.com/blog/2020/05/14/temporal_difference_learning/"},"headline":"vileoy's blog","image":["https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-q6gxpl.png"],"datePublished":"2020-05-14T09:36:09.000Z","dateModified":"2020-10-29T03:40:08.116Z","author":{"@type":"Person","name":"Haoyu Lin"},"description":"In this post, we will now introduce a RL method called TD learning, which can be considered as an improvement or extension of the MC-based RL approach. Similar to the MC technique, TD learning is also"}</script><link rel="canonical" href="https://vileoy.uovie.com/blog/2020/05/14/temporal_difference_learning/"><link rel="icon" href="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-21-favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/blog/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-0-logo.png" alt="vileoy&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/blog/">Home</a><a class="navbar-item" href="/blog/archives">Archives</a><a class="navbar-item" href="/blog/categories">Categories</a><a class="navbar-item" href="/blog/tags">Tags</a><a class="navbar-item" href="/blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/vileoy"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-q6gxpl.png" alt="Temporal Difference Learning"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-05-14T09:36:09.000Z" title="2020-05-14T09:36:09.000Z">2020-05-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-10-29T03:40:08.116Z" title="2020-10-29T03:40:08.116Z">2020-10-29</time></span><span class="level-item"><a class="link-muted" href="/blog/categories/Machine-Learning/">Machine Learning</a><span> / </span><a class="link-muted" href="/blog/categories/Machine-Learning/Reinforcement-Learning/">Reinforcement Learning</a></span><span class="level-item">8 minutes read (About 1266 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Temporal Difference Learning</h1><div class="content"><p>In this post, we will now introduce a RL method called TD learning, which can be considered as an improvement or extension of the MC-based RL approach. Similar to the MC technique, TD learning is also based on learning by experience and, therefore, does not require any knowledge of environment dynamics and transition probabilities.</p>
<a id="more"></a>
<p>The main difference between the TD and MC techniques is that in MC, we have to wait until the end of the episode to be able to calculate the total return. However, in TD learning, we can leverage some of the learned properties to update the estimated values before reaching the end of the episode. This is called <em>bootstrapping</em>.</p>
<p>Similar to the dynamic programming approach and MC-based learning, we will consider two tasks: estimating the value function (which is also called value prediction) and improving the policy (which is also called the control task).</p>
<h2 id="td-prediction">TD prediction</h2>
<p>Let's first revisit the value prediction by MC. At the end of each episode, we are able to estimate the return <span class="math inline">\(G_t\)</span> for each time step <span class="math inline">\(t\)</span>. Therefore, we can update our estimates for the visited states as follows: <span class="math display">\[
V(S_t) = V(S_t) + \alpha (G_t - V(S_t))
\]</span> Here, <span class="math inline">\(G_t\)</span> is used as the target return to update the estimated values, and <span class="math inline">\((G_t − V(S_t))\)</span> is a <em>correction</em> term added to our current estimate of the value <span class="math inline">\(V_(S_t )\)</span>. The value <span class="math inline">\(\alpha\)</span> is a hyperparameter denoting the learning rate, which is kept constant during learning.</p>
<p>Notice that in MC, the correction term uses the actual return, <span class="math inline">\(G_t\)</span> , which is not known until the end of the episode. To clarify this, we can rename the actual return, <span class="math inline">\(G_t\)</span> , to <span class="math inline">\(G_{t:T}\)</span>, where the subscript <span class="math inline">\(t:T\)</span> indicates that this is the return obtained at time step <span class="math inline">\(t\)</span> while considering all the events occurred from time step <span class="math inline">\(t\)</span> until the final time step, <span class="math inline">\(T\)</span>.</p>
<p>In TD learning, we replace the actual return, <span class="math inline">\(G_{t:T}\)</span>, with a new target return, <span class="math inline">\(G_{t:t+1}\)</span>, which significantly simplifies the updates for the value function, <span class="math inline">\(V(S_t)\)</span>. The update-formula based on TD learning is as follows: <span class="math display">\[
V(S_t) = V(S_t) + \alpha (G_{t:t+1} - V(S_t))
\]</span> Here, the target return, <span class="math inline">\(G_{t:t+1} \stackrel{\text{def}}{=} R_{t+1} + \gamma(S_{t+1}) = r + \gamma(S_{t+1})\)</span>, is using the observed reward, <span class="math inline">\(R_{t+1} = r\)</span>, and estimated value of the next immediate step. Notice the difference between MC and TD. In MC, <span class="math inline">\(G_{t:T}\)</span> is not available until the end of the episode, so we should execute as many steps as needed to get there. On the contrary, in TD, we only need to go one step ahead to get the target return. This is also known as TD(0).</p>
<p>Furthermore, the TD(0) algorithm can be generalized to the so-called <em>n-step</em> TD algorithm, which incorporates more future steps – more precisely, the weighted sum of <span class="math inline">\(n\)</span> future steps. If we define <span class="math inline">\(n = 1\)</span>, then the <span class="math inline">\(n\)</span>-step TD procedure is identical to TD(0), which was described in the previous paragraph. If <span class="math inline">\(n \to \infty\)</span>, however, the <span class="math inline">\(n\)</span>-step TD algorithm will be the same as the MC algorithm. The update-rule for <span class="math inline">\(n\)</span>-step TD is as follows: <span class="math display">\[
V(S_t) = V(S_t) + \alpha (G_{t:t+n} - V(S_t))
\]</span> And <span class="math inline">\(G_{t:t+n}\)</span> is defined as: <span class="math display">\[
G_{t:t+n} \stackrel{\text{def}}{=}\left\{\begin{array}{ll}
R_{t+1} + \gamma R_{t+2} + \cdots \gamma^{n-1} R_{t+n} + \gamma^{n} V\left(S_{t+n}\right) &amp; \text{if}\ t+n&lt;T \\
G_{t:T} &amp; \text{otherwise}
\end{array}\right.
\]</span></p>
<blockquote>
<p><strong>MC versus TD: which method converges faster?</strong> While the precise answer to this question is still unknown, in practice, it is empirically shown that TD can converge faster than MC. If you are interested, you can find more details on the convergences of MC and TD in the book titled <em>Reinforcement Learning: An Introduction</em>, by Richard S. Sutton and Andrew G. Barto.</p>
</blockquote>
<p>Now that we have covered the prediction task using the TD algorithm, we can move on to the control task. We will cover two algorithms for TD control: an <em>on-policy</em> control and an <em>off-policy</em> control. In both cases, we use the GPI that was used in both the dynamic programming and MC algorithms. In on-policy TD control, the value function is updated based on the actions from the same policy that the agent is following, while in an off-policy algorithm, the value function is updated based on actions outside the current policy.</p>
<h2 id="on-policy-td-control-sarsa">On-policy TD control (SARSA)</h2>
<p>For simplicity, we only consider the one-step TD algorithm, or TD(0). However, the on-policy TD control algorithm can be readily generalized to <span class="math inline">\(n\)</span>-step TD. We wills tart by extending the prediction formula for defining the state-value function to describe the action-value function. To do this, we use a lookup table, that is, a tabular 2D-array, <span class="math inline">\(Q_(S_t, A_t)\)</span>, which represents the action-value function for each state-action pair. In this case, we will have the following: <span class="math display">\[
Q\left(S_{t}, A_{t}\right)=Q\left(S_{t}, A_{t}\right)+\alpha\left[R_{t+1}+\gamma Q\left(S_{t+1}, A_{t+1}\right)-Q\left(S_{t}, A_{t}\right)\right]
\]</span> This algorithm is often called SARSA, referring to the quintuple <span class="math inline">\((S_t, A_t, R_{t+1}, S_{t+1}, A_{t+1})\)</span> that is used in the update formula. As we saw in the previous sections describing the dynamic programming and MC algorithms, we can use the GPI framework, and starting from the random policy, we can repeatedly estimate the action-value function for the current policy and then optimize the policy using the <span class="math inline">\(\epsilon\)</span>-greedy policy based on the current action-value function.</p>
<h2 id="off-policy-td-control-q-learning">Off-policy TD control (Q-learning)</h2>
<p>We saw when using the previous on-policy TD control algorithm that how we estimate the action-value function is based on the policy that is used in the simulated episode. After updating the action-value function, a separate step for policy improvement is performed by taking the action that has the higher value.</p>
<p>An alternative (and better) approach is to combine these two steps. In other words, imagine the agent is following policy ππ , generating an episode with the current transition quintuple <span class="math inline">\((S_t, A_t, R_{t+1}, S_{t+1}, A_{t+1})\)</span>. Instead of updating the action-value function using the action value of <span class="math inline">\(A_{t+1}\)</span> that is taken by the agent, we can find the best action even if it is not actually chosen by the agent following the current policy. (That's why this is considered an <em>off-policy</em> algorithm.)</p>
<p>To do this, we can modify the update rule to consider the maximum Q-value by varying different actions in the next immediate state. The modified equation for updating the Q-values is as follows: <span class="math display">\[
Q\left(S_{t}, A_{t}\right)=Q\left(S_{t}, A_{t}\right)+\alpha\left[R_{t+1}+\gamma \max_{a} Q\left(S_{t+1}, a\right)-Q\left(S_{t}, A_{t}\right)\right]
\]</span> We encourage you to compare the update rule here with that of the SARSA algorithm. As you can see, we find the best action in the next state, <span class="math inline">\(S_{t+1}\)</span>, and use that in the correction term to update our estimate of <span class="math inline">\(Q(S_t, A_t)\)</span>.</p>
<h2 id="references">References</h2>
<ol type="1">
<li>S. Raschka and V. Mirjalili. <em>Python Machine Learning: Machine Learning and Deep Learning with Python, scikit-learn, and TensorFlow 2</em>. Packt Publishing Ltd, Birmingham, third edition, 2019.</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>Temporal Difference Learning</p><p><a href="https://vileoy.uovie.com/blog/2020/05/14/temporal_difference_learning/">https://vileoy.uovie.com/blog/2020/05/14/temporal_difference_learning/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Haoyu Lin</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-05-14</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2020-10-29</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/blog/tags/Reinforcement-Learning/">Reinforcement Learning</a><a class="link-muted mr-2" rel="tag" href="/blog/tags/Q-Learning/">Q-Learning</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5eb624fd6fa8080012c68782&amp;product=sticky-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/alipay-qrcode.jpg" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wechat-qrcode.png" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/2020/05/14/generating-bibtex-from-doi-arxiv-or-isbn/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Generating BibTeX from DOI, arXiv or ISBN</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/2020/04/12/conda-local-package-auxiliary-installation-scheme/"><span class="level-item">Conda Local-Package-Auxiliary Installation Scheme</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "208882dba79a6540f049dc1fb90c0ed2",
            repo: "blog",
            owner: "vileoy",
            clientID: "7dc49be522b0781c0b39",
            clientSecret: "33315fe6f9dd14cf774f83d746e462de45ebdaeb",
            admin: ["vileoy"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 15,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://cdn.jsdelivr.net/gh/vileoy/source/images/avatar-kousei.jpg" alt="Haoyu Lin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Haoyu Lin</p><p class="is-size-6 is-block">PhD Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Haidian, Beijing, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/blog/archives"><p class="title">26</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/blog/categories"><p class="title">17</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/blog/tags"><p class="title">37</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/vileoy" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/vileoy"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Wechat" href="account:vileoy"><i class="fab fa-weixin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="E-Mail" href="mailto:vileoy@pku.edu.cn"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/vileoy"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/blog/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#td-prediction"><span class="level-left"><span class="level-item">1</span><span class="level-item">TD prediction</span></span></a></li><li><a class="level is-mobile" href="#on-policy-td-control-sarsa"><span class="level-left"><span class="level-item">2</span><span class="level-item">On-policy TD control (SARSA)</span></span></a></li><li><a class="level is-mobile" href="#off-policy-td-control-q-learning"><span class="level-left"><span class="level-item">3</span><span class="level-item">Off-policy TD control (Q-learning)</span></span></a></li><li><a class="level is-mobile" href="#references"><span class="level-left"><span class="level-item">4</span><span class="level-item">References</span></span></a></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/blog/js/toc.js" defer></script></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/09/"><span class="level-start"><span class="level-item">September 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/03/"><span class="level-start"><span class="level-item">March 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/archives/2020/01/"><span class="level-start"><span class="level-item">January 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://uovie.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">UOVIE</span></span><span class="level-right"><span class="level-item tag">uovie.com</span></span></a></li><li><a class="level is-mobile" href="https://lkoit.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">LKOIT</span></span><span class="level-right"><span class="level-item tag">lkoit.com</span></span></a></li><li><a class="level is-mobile" href="https://chemairy.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Chemairy</span></span><span class="level-right"><span class="level-item tag">chemairy.com</span></span></a></li><li><a class="level is-mobile" href="https://fairy.dance" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Fairy Dance</span></span><span class="level-right"><span class="level-item tag">fairy.dance</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/11/24/introduction-to-graph-neural-networks/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/intro-gnn-cover.png" alt="图神经网络简介"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-11-24T08:47:29.035Z">2020-11-24</time></p><p class="title"><a href="/blog/2020/11/24/introduction-to-graph-neural-networks/">图神经网络简介</a></p><p class="categories"><a href="/blog/categories/Machine-Learning/">Machine Learning</a> / <a href="/blog/categories/Machine-Learning/Graph-Neural-Networks/">Graph Neural Networks</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/11/04/music-score-season-song/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-4d31xg.jpg" alt="Music Score: Season Song"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-11-04T03:02:50.000Z">2020-11-04</time></p><p class="title"><a href="/blog/2020/11/04/music-score-season-song/">Music Score: Season Song</a></p><p class="categories"><a href="/blog/categories/Music/">Music</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/10/21/champs-kaggle-competition-predicting-scalar-coupling-constants/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-kwjor6.jpg" alt="Champs Kaggle Competition: Predicting Scalar Coupling Constants"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-10-21T06:58:37.360Z">2020-10-21</time></p><p class="title"><a href="/blog/2020/10/21/champs-kaggle-competition-predicting-scalar-coupling-constants/">Champs Kaggle Competition: Predicting Scalar Coupling Constants</a></p><p class="categories"><a href="/blog/categories/Molecular-Modeling/">Molecular Modeling</a> / <a href="/blog/categories/Molecular-Modeling/Molecular-Property-Prediction/">Molecular Property Prediction</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/10/09/computer-aided-synthesis-planning-a-brief-introduction/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-73v1x3.jpg" alt="Computer-Aided Synthesis Planning: A Brief Introduction"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-10-08T16:21:42.990Z">2020-10-09</time></p><p class="title"><a href="/blog/2020/10/09/computer-aided-synthesis-planning-a-brief-introduction/">Computer-Aided Synthesis Planning: A Brief Introduction</a></p><p class="categories"><a href="/blog/categories/Synthesis-Planning/">Synthesis Planning</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/blog/2020/10/09/message-passing-neural-networks/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/wallhaven-4dk19g.jpg" alt="Message Passing Neural Networks"></a></figure><div class="media-content"><p class="date"><time dateTime="2020-10-08T16:21:42.990Z">2020-10-09</time></p><p class="title"><a href="/blog/2020/10/09/message-passing-neural-networks/">Message Passing Neural Networks</a></p><p class="categories"><a href="/blog/categories/Machine-Learning/">Machine Learning</a> / <a href="/blog/categories/Machine-Learning/Graph-Neural-Networks/">Graph Neural Networks</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/categories/Chemoinformatics/"><span class="level-start"><span class="level-item">Chemoinformatics</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Chemoinformatics/Conventions/"><span class="level-start"><span class="level-item">Conventions</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Game/"><span class="level-start"><span class="level-item">Game</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/LaTeX/"><span class="level-start"><span class="level-item">LaTeX</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Graph-Neural-Networks/"><span class="level-start"><span class="level-item">Graph Neural Networks</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Machine-Learning/Reinforcement-Learning/"><span class="level-start"><span class="level-item">Reinforcement Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Molecular-Dynamics/"><span class="level-start"><span class="level-item">Molecular Dynamics</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Molecular-Dynamics/Free-Energy-Calculation/"><span class="level-start"><span class="level-item">Free Energy Calculation</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Molecular-Modeling/"><span class="level-start"><span class="level-item">Molecular Modeling</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/blog/categories/Molecular-Modeling/Molecular-Property-Prediction/"><span class="level-start"><span class="level-item">Molecular Property Prediction</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Molecular-Modeling/Scoring-Function/"><span class="level-start"><span class="level-item">Scoring Function</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/blog/categories/Music/"><span class="level-start"><span class="level-item">Music</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Parallel-Programming/"><span class="level-start"><span class="level-item">Parallel Programming</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/blog/categories/Synthesis-Planning/"><span class="level-start"><span class="level-item">Synthesis Planning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/blog/tags/Activation-Function/"><span class="tag">Activation Function</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Attention-Mechanism/"><span class="tag">Attention Mechanism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/BibTeX/"><span class="tag">BibTeX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Binding-Affinity/"><span class="tag">Binding Affinity</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/C-Thread-Library/"><span class="tag">C++ Thread Library</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Chrome/"><span class="tag">Chrome</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Conda/"><span class="tag">Conda</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/DOI/"><span class="tag">DOI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Dino/"><span class="tag">Dino</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Free-Energy/"><span class="tag">Free Energy</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Graph/"><span class="tag">Graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/ISBN/"><span class="tag">ISBN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Loss-Function/"><span class="tag">Loss Function</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Matplotlib/"><span class="tag">Matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Message-Passing-Interface/"><span class="tag">Message Passing Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Mol2/"><span class="tag">Mol2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Music-Score/"><span class="tag">Music Score</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Neural-Network/"><span class="tag">Neural Network</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Perturbation-Theory/"><span class="tag">Perturbation Theory</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Protein%E2%88%92Ligand-Complex/"><span class="tag">Protein−Ligand Complex</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Python/"><span class="tag">Python</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Q-Learning/"><span class="tag">Q-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/R/"><span class="tag">R</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/RDKit/"><span class="tag">RDKit</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Reinforcement-Learning/"><span class="tag">Reinforcement Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Retrosynthesis/"><span class="tag">Retrosynthesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Route-Planning/"><span class="tag">Route Planning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/SSH/"><span class="tag">SSH</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Scalar-Coupling/"><span class="tag">Scalar Coupling</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Scoring-Function/"><span class="tag">Scoring Function</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Structure-Preparation/"><span class="tag">Structure Preparation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Tripos/"><span class="tag">Tripos</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Tutorial/"><span class="tag">Tutorial</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/Workflow/"><span class="tag">Workflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/blog/tags/arXiv/"><span class="tag">arXiv</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/blog/"><img src="https://cdn.jsdelivr.net/gh/vileoy/source/images/uovie-icon-0-logo.png" alt="vileoy&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2020 Haoyu Lin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/vileoy"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/blog/js/column.js"></script><script src="/blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>